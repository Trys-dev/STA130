{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c48421",
   "metadata": {},
   "source": [
    "ChatGPT Link: https://chatgpt.com/c/66e369f1-5c68-8013-9050-de0b35bb7eff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a989a4c2",
   "metadata": {},
   "source": [
    "Question 1\n",
    "Pick one of the datasets from the ChatBot session(s) of the TUT demo (or from your own ChatBot session if you wish) and use the code produced through the ChatBot interactions to import the data and confirm that the dataset has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd06dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "missing_values = df.isna().sum()\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb2129",
   "metadata": {},
   "source": [
    "Question 2 Part 1\n",
    "Use code provided in your ChatBot session to print out the number of rows and columns of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edac1587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 391\n",
      "Number of columns: 11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "num_rows, num_columns = df.shape\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a2757",
   "metadata": {},
   "source": [
    "Question 2 Part 2\n",
    "Write your own general definitions of the meaning of \"observations\" and \"variables\" based on asking the ChatBot to explain these terms in the context of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b6a7219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing data:\n",
      "     row_n       id     name  gender   species birthday personality  \\\n",
      "19      23    audie    Audie  female      wolf     8-31       peppy   \n",
      "103    124      cyd      Cyd    male  elephant      6-9      cranky   \n",
      "116    137      dom      Dom    male     sheep     3-18        jock   \n",
      "186    231     judy     Judy  female       cub     3-10      snooty   \n",
      "213    262    louie    Louie    male   gorilla     3-26        jock   \n",
      "230    286    megan    Megan  female      bear     3-13      normal   \n",
      "247    305      NaN      Nan  female      goat     8-24      normal   \n",
      "262    325    paolo    Paolo    male  elephant      5-5        lazy   \n",
      "298    370  raymond  Raymond    male       cat     10-1        smug   \n",
      "300    372  reneigh  Reneigh  female     horse      6-4        uchi   \n",
      "329    406    sherb    Sherb    male      goat     1-18        lazy   \n",
      "337    416    spike    Spike    male     rhino     6-17      cranky   \n",
      "\n",
      "           song      phrase           full_id  \\\n",
      "19          NaN     foxtrot    villager-audie   \n",
      "103         NaN     rockin'      villager-cyd   \n",
      "116         NaN  indeedaroo      villager-dom   \n",
      "186         NaN      myohmy     villager-judy   \n",
      "213         NaN       toots    villager-louie   \n",
      "230         NaN      sundae    villager-megan   \n",
      "247  K.K. Etude         kid      villager-nan   \n",
      "262         NaN         pal    villager-paolo   \n",
      "298         NaN       crisp  villager-raymond   \n",
      "300         NaN    ayup yup  villager-reneigh   \n",
      "329         NaN      bawwww    villager-sherb   \n",
      "337         NaN        punk    villager-spike   \n",
      "\n",
      "                                                   url  \n",
      "19   https://villagerdb.com/images/villagers/thumb/...  \n",
      "103  https://villagerdb.com/images/villagers/thumb/...  \n",
      "116  https://villagerdb.com/images/villagers/thumb/...  \n",
      "186  https://villagerdb.com/images/villagers/thumb/...  \n",
      "213  https://villagerdb.com/images/villagers/thumb/...  \n",
      "230  https://villagerdb.com/images/villagers/thumb/...  \n",
      "247  https://villagerdb.com/images/villagers/thumb/...  \n",
      "262  https://villagerdb.com/images/villagers/thumb/...  \n",
      "298  https://villagerdb.com/images/villagers/thumb/...  \n",
      "300  https://villagerdb.com/images/villagers/thumb/...  \n",
      "329  https://villagerdb.com/images/villagers/thumb/...  \n",
      "337  https://villagerdb.com/images/villagers/thumb/...  \n"
     ]
    }
   ],
   "source": [
    "# Find rows with missing values\n",
    "missing_rows = df[df.isna().any(axis=1)]\n",
    "print(\"Rows with missing data:\")\n",
    "print(missing_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f2d41",
   "metadata": {},
   "source": [
    "Data set:\n",
    "An observations is an individual data point or a record in a dataset. Each observation represents a single instance of the data collected. For instance, in a dataset of villagers, each row might represent a different villager. Basically, this demonstrates that each villager exist in this data set is a observation\n",
    "Variables are attributes or features that are measured and recorded for each observation, which represent different aspects or characteristics of the data. For this case as an example, in the same dataset of villagers, variables \n",
    "include name, species, birthday, gender, and personality, which describe each villager's different attributes. \n",
    "Generally, in observation, Each row in the dataset represents a different villager, so the number of rows (397) indicates the number of observations. The variables here emphasize that each column in the dataset represents a different variable describing the villagers. There are 11 columns for this dataset, so there are 11 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7fd879",
   "metadata": {},
   "source": [
    "Question 3\n",
    "Ask the ChatBot how you can provide simple summaries of the columns in the dataset and use the suggested code to provide these summaries for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60bab823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Structure:\n",
      "Number of rows: 391\n",
      "Number of columns: 11\n",
      "\n",
      "Data types of each column:\n",
      "row_n           int64\n",
      "id             object\n",
      "name           object\n",
      "gender         object\n",
      "species        object\n",
      "birthday       object\n",
      "personality    object\n",
      "song           object\n",
      "phrase         object\n",
      "full_id        object\n",
      "url            object\n",
      "dtype: object\n",
      "\n",
      "Basic Descriptive Statistics (for numerical columns):\n",
      "             row_n       id     name gender species birthday personality  \\\n",
      "count   391.000000      390      391    391     391      391         391   \n",
      "unique         NaN      390      391      2      35      361           8   \n",
      "top            NaN  admiral  Admiral   male     cat     1-27        lazy   \n",
      "freq           NaN        1        1    204      23        2          60   \n",
      "mean    239.902813      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "std     140.702672      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "min       2.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "25%     117.500000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "50%     240.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "75%     363.500000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "max     483.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "\n",
      "                song   phrase           full_id  \\\n",
      "count            380      391               391   \n",
      "unique            92      388               391   \n",
      "top     K.K. Country  wee one  villager-admiral   \n",
      "freq              10        2                 1   \n",
      "mean             NaN      NaN               NaN   \n",
      "std              NaN      NaN               NaN   \n",
      "min              NaN      NaN               NaN   \n",
      "25%              NaN      NaN               NaN   \n",
      "50%              NaN      NaN               NaN   \n",
      "75%              NaN      NaN               NaN   \n",
      "max              NaN      NaN               NaN   \n",
      "\n",
      "                                                      url  \n",
      "count                                                 391  \n",
      "unique                                                391  \n",
      "top     https://villagerdb.com/images/villagers/thumb/...  \n",
      "freq                                                    1  \n",
      "mean                                                  NaN  \n",
      "std                                                   NaN  \n",
      "min                                                   NaN  \n",
      "25%                                                   NaN  \n",
      "50%                                                   NaN  \n",
      "75%                                                   NaN  \n",
      "max                                                   NaN  \n",
      "\n",
      "Counts of Unique Values for Categorical Columns:\n",
      "\n",
      "Value counts for 'id':\n",
      "id\n",
      "admiral    1\n",
      "mott       1\n",
      "paula      1\n",
      "patty      1\n",
      "pate       1\n",
      "          ..\n",
      "eloise     1\n",
      "elmer      1\n",
      "ellie      1\n",
      "elise      1\n",
      "zucker     1\n",
      "Name: count, Length: 390, dtype: int64\n",
      "\n",
      "Value counts for 'name':\n",
      "name\n",
      "Admiral    1\n",
      "Muffy      1\n",
      "Paula      1\n",
      "Patty      1\n",
      "Pate       1\n",
      "          ..\n",
      "Elvis      1\n",
      "Eloise     1\n",
      "Elmer      1\n",
      "Ellie      1\n",
      "Zucker     1\n",
      "Name: count, Length: 391, dtype: int64\n",
      "\n",
      "Value counts for 'gender':\n",
      "gender\n",
      "male      204\n",
      "female    187\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'species':\n",
      "species\n",
      "cat          23\n",
      "rabbit       20\n",
      "frog         18\n",
      "squirrel     18\n",
      "duck         17\n",
      "dog          16\n",
      "cub          16\n",
      "pig          15\n",
      "bear         15\n",
      "mouse        15\n",
      "horse        15\n",
      "bird         13\n",
      "penguin      13\n",
      "sheep        13\n",
      "elephant     11\n",
      "wolf         11\n",
      "ostrich      10\n",
      "deer         10\n",
      "eagle         9\n",
      "gorilla       9\n",
      "chicken       9\n",
      "koala         9\n",
      "goat          8\n",
      "hamster       8\n",
      "kangaroo      8\n",
      "monkey        8\n",
      "anteater      7\n",
      "hippo         7\n",
      "tiger         7\n",
      "alligator     7\n",
      "lion          7\n",
      "bull          6\n",
      "rhino         6\n",
      "cow           4\n",
      "octopus       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'birthday':\n",
      "birthday\n",
      "1-27     2\n",
      "12-5     2\n",
      "7-31     2\n",
      "3-26     2\n",
      "8-3      2\n",
      "        ..\n",
      "4-3      1\n",
      "10-26    1\n",
      "7-23     1\n",
      "12-8     1\n",
      "3-8      1\n",
      "Name: count, Length: 361, dtype: int64\n",
      "\n",
      "Value counts for 'personality':\n",
      "personality\n",
      "lazy      60\n",
      "normal    59\n",
      "cranky    55\n",
      "snooty    55\n",
      "jock      55\n",
      "peppy     49\n",
      "smug      34\n",
      "uchi      24\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'song':\n",
      "song\n",
      "K.K. Country     10\n",
      "Forest Life       9\n",
      "Imperial K.K.     7\n",
      "K.K. Soul         7\n",
      "K.K. Ragtime      7\n",
      "                 ..\n",
      "Aloha K.K.        2\n",
      "Drivin'           1\n",
      "Senor K.K.        1\n",
      "K.K.  Bazaar      1\n",
      "K.K. D&B          1\n",
      "Name: count, Length: 92, dtype: int64\n",
      "\n",
      "Value counts for 'phrase':\n",
      "phrase\n",
      "wee one       2\n",
      "quacko        2\n",
      "bloop         2\n",
      "aye aye       1\n",
      "snoot         1\n",
      "             ..\n",
      "lambchop      1\n",
      "yeah buddy    1\n",
      "chow down     1\n",
      "unh-hunh      1\n",
      "pronk         1\n",
      "Name: count, Length: 388, dtype: int64\n",
      "\n",
      "Value counts for 'full_id':\n",
      "full_id\n",
      "villager-admiral    1\n",
      "villager-muffy      1\n",
      "villager-paula      1\n",
      "villager-patty      1\n",
      "villager-pate       1\n",
      "                   ..\n",
      "villager-elvis      1\n",
      "villager-eloise     1\n",
      "villager-elmer      1\n",
      "villager-ellie      1\n",
      "villager-zucker     1\n",
      "Name: count, Length: 391, dtype: int64\n",
      "\n",
      "Value counts for 'url':\n",
      "url\n",
      "https://villagerdb.com/images/villagers/thumb/admiral.98206ee.png    1\n",
      "https://villagerdb.com/images/villagers/thumb/muffy.1497c92.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/paula.563ba81.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/patty.3e17f7f.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/pate.c60838c.png       1\n",
      "                                                                    ..\n",
      "https://villagerdb.com/images/villagers/thumb/elvis.57d4757.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/eloise.112208b.png     1\n",
      "https://villagerdb.com/images/villagers/thumb/elmer.cc7df52.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/ellie.5a144a6.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/zucker.8dbb719.png     1\n",
      "Name: count, Length: 391, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 1. Overview of DataFrame Structure\n",
    "print(\"DataFrame Structure:\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nData types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 2. Basic Descriptive Statistics\n",
    "print(\"\\nBasic Descriptive Statistics (for numerical columns):\")\n",
    "print(df.describe(include='all'))  # include='all' to get stats for all column types\n",
    "\n",
    "# 3. Counts of Unique Values for Categorical Columns\n",
    "print(\"\\nCounts of Unique Values for Categorical Columns:\")\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    print(f\"\\nValue counts for '{column}':\")\n",
    "    print(df[column].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34683db3",
   "metadata": {},
   "source": [
    "Definitons for the DataFrame Structure of the data:\n",
    "[df.shape] gives the number of rows and columns.\n",
    "[df.dtypes] provides the data types of each column.\n",
    "Definitions for the Basic Descriptive Statistics of the data:\n",
    "df.describe(include='all') provides summary statistics for all columns, including categorical ones. Specifically, [df. describe] includes counts, unique values, top values, and frequency for categorical columns.\n",
    "Definitions for the Counts of Unique Values of the data:\n",
    "Loop through categorical columns [(df.select_dtypes(include='object'))] and use [value_counts()] to see the distribution of values in each column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7a881",
   "metadata": {},
   "source": [
    "Question 4\n",
    "If the dataset you're using has (a) non-numeric variables and (b) missing values in numeric variables, explain (perhaps using help from a ChatBot if needed) the discrepancies between size of the dataset given by df.shape and what is reported by df.describe() with respect to (a) the number of columns it analyzes and (b) the values it reports in the \"count\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "668cd986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Structure:\n",
      "Number of rows: 891\n",
      "Number of columns: 15\n",
      "\n",
      "Data types of each column:\n",
      "survived         int64\n",
      "pclass           int64\n",
      "sex             object\n",
      "age            float64\n",
      "sibsp            int64\n",
      "parch            int64\n",
      "fare           float64\n",
      "embarked        object\n",
      "class           object\n",
      "who             object\n",
      "adult_male        bool\n",
      "deck            object\n",
      "embark_town     object\n",
      "alive           object\n",
      "alone             bool\n",
      "dtype: object\n",
      "\n",
      "Basic Descriptive Statistics (for numerical columns):\n",
      "          survived      pclass   sex         age       sibsp       parch  \\\n",
      "count   891.000000  891.000000   891  714.000000  891.000000  891.000000   \n",
      "unique         NaN         NaN     2         NaN         NaN         NaN   \n",
      "top            NaN         NaN  male         NaN         NaN         NaN   \n",
      "freq           NaN         NaN   577         NaN         NaN         NaN   \n",
      "mean      0.383838    2.308642   NaN   29.699118    0.523008    0.381594   \n",
      "std       0.486592    0.836071   NaN   14.526497    1.102743    0.806057   \n",
      "min       0.000000    1.000000   NaN    0.420000    0.000000    0.000000   \n",
      "25%       0.000000    2.000000   NaN   20.125000    0.000000    0.000000   \n",
      "50%       0.000000    3.000000   NaN   28.000000    0.000000    0.000000   \n",
      "75%       1.000000    3.000000   NaN   38.000000    1.000000    0.000000   \n",
      "max       1.000000    3.000000   NaN   80.000000    8.000000    6.000000   \n",
      "\n",
      "              fare embarked  class  who adult_male deck  embark_town alive  \\\n",
      "count   891.000000      889    891  891        891  203          889   891   \n",
      "unique         NaN        3      3    3          2    7            3     2   \n",
      "top            NaN        S  Third  man       True    C  Southampton    no   \n",
      "freq           NaN      644    491  537        537   59          644   549   \n",
      "mean     32.204208      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "std      49.693429      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "min       0.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "25%       7.910400      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "50%      14.454200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "75%      31.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "max     512.329200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "\n",
      "       alone  \n",
      "count    891  \n",
      "unique     2  \n",
      "top     True  \n",
      "freq     537  \n",
      "mean     NaN  \n",
      "std      NaN  \n",
      "min      NaN  \n",
      "25%      NaN  \n",
      "50%      NaN  \n",
      "75%      NaN  \n",
      "max      NaN  \n",
      "\n",
      "Counts of Unique Values for Categorical Columns:\n",
      "\n",
      "Value counts for 'sex':\n",
      "sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'embarked':\n",
      "embarked\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'class':\n",
      "class\n",
      "Third     491\n",
      "First     216\n",
      "Second    184\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'who':\n",
      "who\n",
      "man      537\n",
      "woman    271\n",
      "child     83\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'deck':\n",
      "deck\n",
      "C    59\n",
      "B    47\n",
      "D    33\n",
      "E    32\n",
      "A    15\n",
      "F    13\n",
      "G     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'embark_town':\n",
      "embark_town\n",
      "Southampton    644\n",
      "Cherbourg      168\n",
      "Queenstown      77\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'alive':\n",
      "alive\n",
      "no     549\n",
      "yes    342\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 1. Overview of DataFrame Structure\n",
    "print(\"DataFrame Structure:\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nData types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 2. Basic Descriptive Statistics\n",
    "print(\"\\nBasic Descriptive Statistics (for numerical columns):\")\n",
    "print(df.describe(include='all'))  # include='all' to get stats for all column types\n",
    "\n",
    "# 3. Counts of Unique Values for Categorical Columns\n",
    "print(\"\\nCounts of Unique Values for Categorical Columns:\")\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    print(f\"\\nValue counts for '{column}':\")\n",
    "    print(df[column].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba6874",
   "metadata": {},
   "source": [
    "For the alternative data set, we are able to observe that the data set did not include any empty columns or rows. However, the row for age does not match with the number with the rest of the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f893b",
   "metadata": {},
   "source": [
    "Question 5\n",
    "Use your ChatBot session to help understand the difference between the following and then provide your own paraphrasing summarization of that difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "788eced9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)  # Outputs (397, 11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7259aeba",
   "metadata": {},
   "source": [
    "Parentheses () must be called even in case a method doesn't accept any parameters. The method's defined action is being invoked, as shown by the parenthesis. One such method on a DataFrame object is df.describe(). It computes the summary statistics for the columns in the DataFrame. This computation is started by calling df.describe(), which returns the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dad949a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())  # Outputs summary statistics for numerical columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0017094e",
   "metadata": {},
   "source": [
    "Features (such as df.shape): Provides immediate access to data or state information. Parentheses are not required. Methods: Used to carry out calculations or operations (e.g., df.describe()). It takes parentheses to refer to them. Knowing the difference between accessing data and performing an action makes utilizing the pandas library and other Python objects more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7dabda",
   "metadata": {},
   "source": [
    "Question 6\n",
    "The df.describe() method provides the 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max' summary statistics for each variable it analyzes. Give the definitions (perhaps using help from the ChatBot if needed) of each of these summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130fc0ad",
   "metadata": {},
   "source": [
    "The definition of count is the number of non-null (non-missing) values in the column which indicates how many entries are present in the column out of the total number of rows.\n",
    "The mean of the dataset is the average value of the column, which is the sum of all values divided by the number of non-null entries. It’s a measure of central tendency.\n",
    "Std (Standard Deviation) is the measurement the dispersion or spread of the values around the mean. By definition, meaning a higher standard deviation indicates more variability from the mean.\n",
    "The Min (Minimum) is the smallest value in the column Provides the lowest data point.\n",
    "25% (25th Percentile) or the First Quartile is the value below which 25% of the data falls.This indicates the point below which one-quarter of the data lies.\n",
    "50% (50th Percentile) or the Median is the middle value of the column when the data is sorted.This means that half of the data is below this value, and half is above it. It’s a measure of central tendency.\n",
    "75% (75th Percentile) or the Third Quartile is the value below which 75% of the data falls. Meaning the point below which three-quarters of the data lies.\n",
    "The Max (Maximum) is the largest value in the column, which Provides the highest data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a20acac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             row_n       id     name gender species birthday personality  \\\n",
      "count   391.000000      390      391    391     391      391         391   \n",
      "unique         NaN      390      391      2      35      361           8   \n",
      "top            NaN  admiral  Admiral   male     cat     1-27        lazy   \n",
      "freq           NaN        1        1    204      23        2          60   \n",
      "mean    239.902813      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "std     140.702672      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "min       2.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "25%     117.500000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "50%     240.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "75%     363.500000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "max     483.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "\n",
      "                song   phrase           full_id  \\\n",
      "count            380      391               391   \n",
      "unique            92      388               391   \n",
      "top     K.K. Country  wee one  villager-admiral   \n",
      "freq              10        2                 1   \n",
      "mean             NaN      NaN               NaN   \n",
      "std              NaN      NaN               NaN   \n",
      "min              NaN      NaN               NaN   \n",
      "25%              NaN      NaN               NaN   \n",
      "50%              NaN      NaN               NaN   \n",
      "75%              NaN      NaN               NaN   \n",
      "max              NaN      NaN               NaN   \n",
      "\n",
      "                                                      url  \n",
      "count                                                 391  \n",
      "unique                                                391  \n",
      "top     https://villagerdb.com/images/villagers/thumb/...  \n",
      "freq                                                    1  \n",
      "mean                                                  NaN  \n",
      "std                                                   NaN  \n",
      "min                                                   NaN  \n",
      "25%                                                   NaN  \n",
      "50%                                                   NaN  \n",
      "75%                                                   NaN  \n",
      "max                                                   NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get descriptive statistics for all columns\n",
    "summary_statistics = df.describe(include='all')\n",
    "\n",
    "print(summary_statistics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab98ca",
   "metadata": {},
   "source": [
    "This demonstrates how to use df.describe() and interpret these statistics for each variable in your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2b6227",
   "metadata": {},
   "source": [
    "               numerical_column\n",
    "count                        397\n",
    "mean                          50.3\n",
    "std                           12.4\n",
    "min                           10.0\n",
    "25%                           40.0\n",
    "50%                           50.0\n",
    "75%                           60.0\n",
    "max                           90.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d3d590",
   "metadata": {},
   "source": [
    "In this Scenario:\n",
    "The Count: 397 values are present.\n",
    "The mean of the average value is 50.3.\n",
    "The standard deviation is 12.4, indicating the spread of values around the mean.\n",
    "The Mininum, which the smallest value is 10.0.\n",
    "25%: 25% of the values are below 40.0.\n",
    "50%: The median value is 50.0.\n",
    "75%: 75% of the values are below 60.0.\n",
    "The Maximum, which the largest value is 90.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698990ac",
   "metadata": {},
   "source": [
    "Question 7\n",
    "Missing data can be considered \"across rows\" or \"down columns\". Consider how df.dropna() or del df['col'] should be applied to most efficiently use the available non-missing data in your dataset and briefly answer the following questions in your own words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d3b5a",
   "metadata": {},
   "source": [
    "Part 1: Provide an example of a \"use case\" in which using df.dropna() might be peferred over using del df['col']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473e4512",
   "metadata": {},
   "source": [
    "[df.dropna()] is used to remove rows or columns with missing values (NaNs) from the DataFrame.Usually this method is preferred when you want to clean your data by removing any rows or columns that contain missing values, which might be necessary if those missing values could affect the analysis or if the missing data represents a significant portion of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b976c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   review_id review_text  rating        date\n",
      "0          1        Good     5.0  2024-01-01\n",
      "2          3        None     3.0  2024-01-03\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'review_id': [1, 2, 3, 4],\n",
    "    'review_text': ['Good', 'Average', None, 'Excellent'],\n",
    "    'rating': [5, None, 3, None],\n",
    "    'date': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop rows where 'rating' is missing\n",
    "df_cleaned = df.dropna(subset=['rating'])\n",
    "\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6d32b",
   "metadata": {},
   "source": [
    "[del df['col']] is used to delete an entire column from the DataFrame. Generally, this method is appropriate when you want to completely remove a column from your DataFrame, regardless of whether it contains missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb0d8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id         name  price  availability\n",
      "0         101       Widget  19.99      In Stock\n",
      "1         102       Gadget  29.99  Out of Stock\n",
      "2         103       Doodad   9.99      In Stock\n",
      "3         104  Thingamajig  14.99      In Stock\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'product_id': [101, 102, 103, 104],\n",
    "    'name': ['Widget', 'Gadget', 'Doodad', 'Thingamajig'],\n",
    "    'price': [19.99, 29.99, 9.99, 14.99],\n",
    "    'discount': [1.00, None, 0.50, None],\n",
    "    'availability': ['In Stock', 'Out of Stock', 'In Stock', 'In Stock']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Delete the 'discount' column\n",
    "del df['discount']\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dcf229",
   "metadata": {},
   "source": [
    "In conclusion, I would prefer using [df.dropna()] when you need to remove rows or columns with missing values to maintain the integrity of the data set, which is what we're looking for. I would suggest to use del df['col'] when you want to completely remove a column from the DataFrame, regardless of its content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70767f6",
   "metadata": {},
   "source": [
    "Part 2: Provide an example of \"the opposite use case\" in which using del df['col'] might be preferred over using df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c092dda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   employee_id     name  salary department     address\n",
      "0            1    Alice   70000         HR  123 Elm St\n",
      "1            2      Bob   80000    Finance        None\n",
      "2            3  Charlie   90000         IT  456 Oak St\n",
      "3            4    David  100000  Marketing        None\n",
      "\n",
      "DataFrame after removing 'address' column:\n",
      "   employee_id     name  salary department\n",
      "0            1    Alice   70000         HR\n",
      "1            2      Bob   80000    Finance\n",
      "2            3  Charlie   90000         IT\n",
      "3            4    David  100000  Marketing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'employee_id': [1, 2, 3, 4],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'salary': [70000, 80000, 90000, 100000],\n",
    "    'department': ['HR', 'Finance', 'IT', 'Marketing'],\n",
    "    'address': ['123 Elm St', None, '456 Oak St', None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Remove the 'address' column\n",
    "del df['address']\n",
    "\n",
    "print(\"\\nDataFrame after removing 'address' column:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049204c0",
   "metadata": {},
   "source": [
    "In particular, the reason to use [del df['col']] might be preferred over using [df.dropna()] is that the address column is deemed irrelevant for the analysis, and its removal simplifies the DataFrame. Furthermore, there is no need for data cleaning in this case. Since the column is not required, there's no need to handle missing values in that column. Removing the entire column is cleaner and more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9af0ff",
   "metadata": {},
   "source": [
    "Part 3: Discuss why applying del df['col'] before df.dropna() when both are used together could be important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407f2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after removing 'address' column and handling missing values:\n",
      "   employee_id     name   salary department date_of_birth\n",
      "0            1    Alice  70000.0         HR    1990-01-01\n",
      "2            3  Charlie  90000.0         IT    1985-05-12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'employee_id': [1, 2, 3, 4],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'salary': [70000, None, 90000, None],\n",
    "    'department': ['HR', 'Finance', 'IT', 'Marketing'],\n",
    "    'address': ['123 Elm St', None, '456 Oak St', None],\n",
    "    'date_of_birth': ['1990-01-01', None, '1985-05-12', None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove irrelevant column 'address'\n",
    "del df['address']\n",
    "\n",
    "# Apply dropna() to handle missing values in remaining columns\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "print(\"DataFrame after removing 'address' column and handling missing values:\")\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca897a92",
   "metadata": {},
   "source": [
    "It is significant when applying [del df['col']] before [df.dropna()] when ensuring when working with a cleaner dataset by first removing unnecessary columns and then handling missing data. Reducing the dataset’s size and complexity can make the [df.dropna()] operation more efficient. It also helps prevent mistakes from [del df['col']]that occur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac2317f",
   "metadata": {},
   "source": [
    "Part 4: Remove all missing data from one of the datasets you're considering using some combination of del df['col'] and/or df.dropna() and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf145cb",
   "metadata": {},
   "source": [
    "Before: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f1eb5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data before cleaning:\n",
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n",
      "\n",
      "Missing data after cleaning:\n",
      "row_n          0\n",
      "id             0\n",
      "name           0\n",
      "gender         0\n",
      "species        0\n",
      "birthday       0\n",
      "personality    0\n",
      "song           0\n",
      "phrase         0\n",
      "full_id        0\n",
      "url            0\n",
      "dtype: int64\n",
      "\n",
      "Original DataFrame:\n",
      "   row_n       id     name  gender    species birthday personality  \\\n",
      "0      2  admiral  Admiral    male       bird     1-27      cranky   \n",
      "1      3  agent-s  Agent S  female   squirrel      7-2       peppy   \n",
      "2      4    agnes    Agnes  female        pig     4-21        uchi   \n",
      "3      6       al       Al    male    gorilla    10-18        lazy   \n",
      "4      7  alfonso  Alfonso    male  alligator      6-9        lazy   \n",
      "\n",
      "          song    phrase           full_id  \\\n",
      "0   Steep Hill   aye aye  villager-admiral   \n",
      "1      DJ K.K.  sidekick  villager-agent-s   \n",
      "2   K.K. House   snuffle    villager-agnes   \n",
      "3   Steep Hill   Ayyeeee       villager-al   \n",
      "4  Forest Life  it'sa me  villager-alfonso   \n",
      "\n",
      "                                                 url  \n",
      "0  https://villagerdb.com/images/villagers/thumb/...  \n",
      "1  https://villagerdb.com/images/villagers/thumb/...  \n",
      "2  https://villagerdb.com/images/villagers/thumb/...  \n",
      "3  https://villagerdb.com/images/villagers/thumb/...  \n",
      "4  https://villagerdb.com/images/villagers/thumb/...  \n",
      "\n",
      "Cleaned DataFrame:\n",
      "   row_n       id     name  gender    species birthday personality  \\\n",
      "0      2  admiral  Admiral    male       bird     1-27      cranky   \n",
      "1      3  agent-s  Agent S  female   squirrel      7-2       peppy   \n",
      "2      4    agnes    Agnes  female        pig     4-21        uchi   \n",
      "3      6       al       Al    male    gorilla    10-18        lazy   \n",
      "4      7  alfonso  Alfonso    male  alligator      6-9        lazy   \n",
      "\n",
      "          song    phrase           full_id  \\\n",
      "0   Steep Hill   aye aye  villager-admiral   \n",
      "1      DJ K.K.  sidekick  villager-agent-s   \n",
      "2   K.K. House   snuffle    villager-agnes   \n",
      "3   Steep Hill   Ayyeeee       villager-al   \n",
      "4  Forest Life  it'sa me  villager-alfonso   \n",
      "\n",
      "                                                 url  \n",
      "0  https://villagerdb.com/images/villagers/thumb/...  \n",
      "1  https://villagerdb.com/images/villagers/thumb/...  \n",
      "2  https://villagerdb.com/images/villagers/thumb/...  \n",
      "3  https://villagerdb.com/images/villagers/thumb/...  \n",
      "4  https://villagerdb.com/images/villagers/thumb/...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Step 1: Identify columns with missing data\n",
    "missing_data_before = df.isna().sum()\n",
    "print(\"Missing data before cleaning:\")\n",
    "print(missing_data_before)\n",
    "\n",
    "# Step 2: Remove irrelevant columns with excessive missing data\n",
    "# Let's assume 'image_url' is deemed irrelevant\n",
    "if 'image_url' in df.columns:\n",
    "    del df['image_url']\n",
    "\n",
    "# Step 3: Remove rows with missing data in relevant columns\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Step 4: Report missing data after cleaning\n",
    "missing_data_after = df_cleaned.isna().sum()\n",
    "print(\"\\nMissing data after cleaning:\")\n",
    "print(missing_data_after)\n",
    "\n",
    "# Display before and after DataFrames for comparison\n",
    "print(\"\\nOriginal DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f2c8e6",
   "metadata": {},
   "source": [
    "First apply [del df['col']] to remove columns that are not needed for analysis and that have significant missing data. Then use [df.dropna()] to remove rows with missing values in columns that are important for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244a3ffb",
   "metadata": {},
   "source": [
    "After:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5156741c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data before cleaning:\n",
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n",
      "\n",
      "Missing data after cleaning:\n",
      "row_n          0\n",
      "id             0\n",
      "name           0\n",
      "gender         0\n",
      "species        0\n",
      "birthday       0\n",
      "personality    0\n",
      "song           0\n",
      "phrase         0\n",
      "full_id        0\n",
      "url            0\n",
      "dtype: int64\n",
      "\n",
      "Original DataFrame:\n",
      "   row_n       id     name  gender    species birthday personality  \\\n",
      "0      2  admiral  Admiral    male       bird     1-27      cranky   \n",
      "1      3  agent-s  Agent S  female   squirrel      7-2       peppy   \n",
      "2      4    agnes    Agnes  female        pig     4-21        uchi   \n",
      "3      6       al       Al    male    gorilla    10-18        lazy   \n",
      "4      7  alfonso  Alfonso    male  alligator      6-9        lazy   \n",
      "\n",
      "          song    phrase           full_id  \\\n",
      "0   Steep Hill   aye aye  villager-admiral   \n",
      "1      DJ K.K.  sidekick  villager-agent-s   \n",
      "2   K.K. House   snuffle    villager-agnes   \n",
      "3   Steep Hill   Ayyeeee       villager-al   \n",
      "4  Forest Life  it'sa me  villager-alfonso   \n",
      "\n",
      "                                                 url  \n",
      "0  https://villagerdb.com/images/villagers/thumb/...  \n",
      "1  https://villagerdb.com/images/villagers/thumb/...  \n",
      "2  https://villagerdb.com/images/villagers/thumb/...  \n",
      "3  https://villagerdb.com/images/villagers/thumb/...  \n",
      "4  https://villagerdb.com/images/villagers/thumb/...  \n",
      "\n",
      "Cleaned DataFrame:\n",
      "   row_n       id     name  gender    species birthday personality  \\\n",
      "0      2  admiral  Admiral    male       bird     1-27      cranky   \n",
      "1      3  agent-s  Agent S  female   squirrel      7-2       peppy   \n",
      "2      4    agnes    Agnes  female        pig     4-21        uchi   \n",
      "3      6       al       Al    male    gorilla    10-18        lazy   \n",
      "4      7  alfonso  Alfonso    male  alligator      6-9        lazy   \n",
      "\n",
      "          song    phrase           full_id  \\\n",
      "0   Steep Hill   aye aye  villager-admiral   \n",
      "1      DJ K.K.  sidekick  villager-agent-s   \n",
      "2   K.K. House   snuffle    villager-agnes   \n",
      "3   Steep Hill   Ayyeeee       villager-al   \n",
      "4  Forest Life  it'sa me  villager-alfonso   \n",
      "\n",
      "                                                 url  \n",
      "0  https://villagerdb.com/images/villagers/thumb/...  \n",
      "1  https://villagerdb.com/images/villagers/thumb/...  \n",
      "2  https://villagerdb.com/images/villagers/thumb/...  \n",
      "3  https://villagerdb.com/images/villagers/thumb/...  \n",
      "4  https://villagerdb.com/images/villagers/thumb/...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Step 1: Identify columns with missing data\n",
    "missing_data_before = df.isna().sum()\n",
    "print(\"Missing data before cleaning:\")\n",
    "print(missing_data_before)\n",
    "\n",
    "# Step 2: Remove irrelevant columns with excessive missing data\n",
    "# Let's assume 'image_url' is deemed irrelevant\n",
    "if 'image_url' in df.columns:\n",
    "    del df['image_url']\n",
    "\n",
    "# Step 3: Remove rows with missing data in relevant columns\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Step 4: Report missing data after cleaning\n",
    "missing_data_after = df_cleaned.isna().sum()\n",
    "print(\"\\nMissing data after cleaning:\")\n",
    "print(missing_data_after)\n",
    "\n",
    "# Display before and after DataFrames for comparison\n",
    "print(\"\\nOriginal DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e8767",
   "metadata": {},
   "source": [
    "By removing the [image_url column], we eliminate a column with significant missing data that does not relate to the analysis.Then we use df.dropna() to ensure that only rows with complete data in the remaining columns are kept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19f0ff9",
   "metadata": {},
   "source": [
    "Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80581918",
   "metadata": {},
   "source": [
    "Part 1: Use your ChatBot session to understand what df.groupby(\"col1\")[\"col2\"].describe() does and then demonstrate and explain this using a different example from the \"titanic\" data set other than what the ChatBot automatically provide for you"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb62419",
   "metadata": {},
   "source": [
    "According to chatbot, the [groupby()] method in pandas is used to group the DataFrame by one or more columns, allowing you to perform aggregate operations on other columns within those groups. On the other hand, the [describe()] method provides summary statistics (e.g., count, mean, standard deviation, min, max, and quartiles) for a specific column.\n",
    "\n",
    "[df.groupby(\"col1\")]: The data is grouped by the values in col1. This means that all rows with the same value in col1 will be considered together as a group.\n",
    "\n",
    "[\"col2\"]: This specifies that you want to perform operations on col2 after grouping by col1.\n",
    "\n",
    "[.describe()]:After grouping, .describe() is applied to the values of col2 within each group, providing summary statistics for col2 for each group formed by col1.\n",
    "\n",
    "Demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d314c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           count       mean        std   min    25%   50%    75%    max\n",
      "species                                                                \n",
      "alligator    7.0  74.285714  15.118579  55.0  65.00  75.0  80.00  100.0\n",
      "anteater     7.0  59.285714  17.423301  40.0  47.50  60.0  65.00   90.0\n",
      "bear        15.0  70.333333  20.041623  30.0  62.50  75.0  80.00  100.0\n",
      "bird        13.0  68.846154  18.045526  30.0  60.00  70.0  80.00  100.0\n",
      "bull         6.0  80.833333  14.972196  55.0  80.00  80.0  87.50  100.0\n",
      "cat         23.0  65.000000  19.771421  30.0  55.00  70.0  80.00  100.0\n",
      "chicken      9.0  71.666667  21.360009  30.0  55.00  75.0  90.00   90.0\n",
      "cow          4.0  87.500000  10.408330  75.0  82.50  87.5  92.50  100.0\n",
      "cub         16.0  68.437500  28.090256  30.0  40.00  72.5  92.50  100.0\n",
      "deer        10.0  64.000000  23.428378  30.0  43.75  72.5  83.75   90.0\n",
      "dog         16.0  66.875000  20.564938  30.0  55.00  70.0  85.00  100.0\n",
      "duck        17.0  63.235294  20.912106  30.0  40.00  75.0  80.00  100.0\n",
      "eagle        9.0  71.666667  21.360009  30.0  60.00  75.0  90.00  100.0\n",
      "elephant    11.0  77.272727  22.952520  30.0  72.50  85.0  90.00  100.0\n",
      "frog        18.0  75.277778  21.315020  30.0  58.75  77.5  90.00  100.0\n",
      "goat         8.0  60.625000  23.212912  30.0  48.75  57.5  81.25   90.0\n",
      "gorilla      9.0  65.000000  21.650635  30.0  55.00  60.0  85.00   90.0\n",
      "hamster      8.0  60.625000  28.465204  30.0  37.50  57.5  85.00  100.0\n",
      "hippo        7.0  68.571429  17.008401  40.0  62.50  70.0  77.50   90.0\n",
      "horse       15.0  77.333333  14.984119  60.0  65.00  75.0  87.50  100.0\n",
      "kangaroo     8.0  70.000000  16.903085  40.0  58.75  75.0  85.00   85.0\n",
      "koala        9.0  50.000000  23.048861  30.0  30.00  40.0  70.00   85.0\n",
      "lion         7.0  66.428571  20.354010  40.0  55.00  60.0  77.50  100.0\n",
      "monkey       8.0  82.500000  14.142136  60.0  73.75  82.5  92.50  100.0\n",
      "mouse       15.0  65.666667  23.289074  30.0  40.00  70.0  80.00  100.0\n",
      "octopus      3.0  66.666667  32.145503  30.0  55.00  80.0  85.00   90.0\n",
      "ostrich     10.0  59.000000  26.012817  30.0  32.50  60.0  77.50  100.0\n",
      "penguin     13.0  72.307692  21.853240  30.0  60.00  80.0  85.00  100.0\n",
      "pig         15.0  69.333333  22.429785  30.0  55.00  75.0  87.50  100.0\n",
      "rabbit      20.0  72.500000  15.517393  40.0  67.50  75.0  81.25  100.0\n",
      "rhino        6.0  70.833333  23.961775  30.0  63.75  75.0  82.50  100.0\n",
      "sheep       13.0  68.461538  19.831017  40.0  55.00  75.0  80.00  100.0\n",
      "squirrel    18.0  60.555556  20.211302  30.0  43.75  57.5  77.50  100.0\n",
      "tiger        7.0  73.571429  28.389300  30.0  55.00  85.0  95.00  100.0\n",
      "wolf        11.0  68.181818  19.908883  30.0  57.50  60.0  82.50  100.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Add a hypothetical numerical column called 'popularity_score'\n",
    "# Use np.tile to repeat the list and match the length of the DataFrame\n",
    "popularity_scores = [80, 55, 75, 90, 60, 40, 100, 30, 70, 85]\n",
    "df['popularity_score'] = np.tile(popularity_scores, len(df) // len(popularity_scores) + 1)[:len(df)]\n",
    "\n",
    "# Group by 'species' and get descriptive statistics for 'popularity_score'\n",
    "grouped_stats = df.groupby('species')['popularity_score'].describe()\n",
    "\n",
    "print(grouped_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452ef73",
   "metadata": {},
   "source": [
    "Part 2:Assuming you've not yet removed missing values in the manner of question \"7\" above, df.describe() would have different values in the count value for different data columns depending on the missingness present in the original data. Why do these capture something fundamentally different from the values in the count that result from doing something like df.groupby(\"col1\")[\"col2\"].describe()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71127fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.describe():\n",
      "       popularity_score\n",
      "count          5.000000\n",
      "mean          80.000000\n",
      "std            7.905694\n",
      "min           70.000000\n",
      "25%           75.000000\n",
      "50%           80.000000\n",
      "75%           85.000000\n",
      "max           90.000000\n",
      "\n",
      "Grouped describe():\n",
      "         count  mean        std   min    25%   50%    75%   max\n",
      "species                                                        \n",
      "Bird       2.0  77.5  10.606602  70.0  73.75  77.5  81.25  85.0\n",
      "Cat        2.0  85.0   7.071068  80.0  82.50  85.0  87.50  90.0\n",
      "Dog        1.0  75.0        NaN  75.0  75.00  75.0  75.00  75.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'species': ['Cat', 'Cat', 'Dog', 'Dog', 'Bird', 'Bird', 'Bird'],\n",
    "    'popularity_score': [80, 90, 75, None, 85, None, 70]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# df.describe() - provides summary statistics for each column, including the count of non-missing values\n",
    "df_description = df.describe()\n",
    "\n",
    "# df.groupby('species')['popularity_score'].describe() - groups by species and gives summary statistics for popularity_score\n",
    "grouped_description = df.groupby('species')['popularity_score'].describe()\n",
    "\n",
    "print(\"df.describe():\")\n",
    "print(df_description)\n",
    "\n",
    "print(\"\\nGrouped describe():\")\n",
    "print(grouped_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa337f",
   "metadata": {},
   "source": [
    "Any missing values in a column reduce the count for that specific column. For example, if you have 100 rows but 10 of them have missing values in col2, the count for col2 will be 90 in the summary provided by [df.describe()], but it will still count all valid values for other columns. With this saying, when applying df.groupby(\"col1\")[\"col2\"].describe(), the count refers to the number of non-missing observations of col2 within each group defined by the values in col1. \n",
    "\n",
    " Output of df.groupby('species').describe():\n",
    " count  mean       std   min    25%   50%    75%    max\n",
    "species                                                        \n",
    "Bird       2.0   77.5  10.6066  70.0   73.75  77.5   81.25   85.0\n",
    "Cat        2.0   85.0   7.0711  80.0   82.50  85.0   87.50   90.0\n",
    "Dog        1.0   75.0      NaN  75.0   75.00  75.0   75.00   75.0\n",
    "\n",
    "Demonstrated by the groupby() output, the count shows how many non-missing values exist for popularity_score within each species. For example, there are 2 non-missing values for Bird and Cat, and only 1 non-missing value for Dog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b54974",
   "metadata": {},
   "source": [
    "Part 3: Intentionally introduce the following errors into your code and report your opinion as to whether it's easier to (a) work in a ChatBot session to fix the errors, or (b) use google to search for and fix errors: first share the errors you get in the ChatBot session and see if you can work with ChatBot to troubleshoot and fix the coding errors, and then see if you think a google search for the error provides the necessary toubleshooting help more quickly than ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6080b9",
   "metadata": {},
   "source": [
    "a.Forget to include import pandas as pd in your code\n",
    "Use Kernel->Restart from the notebook menu to restart the jupyter notebook session unload imported libraries and start over so you can create this error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05dcdcff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Step 1: Identify columns with missing data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m missing_data_before \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Step 1: Identify columns with missing data\n",
    "missing_data_before = df.isna().sum()\n",
    "print(\"Missing data before cleaning:\")\n",
    "print(missing_data_before)\n",
    "\n",
    "# Step 2: Remove irrelevant columns with excessive missing data\n",
    "# Let's assume 'image_url' is deemed irrelevant\n",
    "if 'image_url' in df.columns:\n",
    "    del df['image_url']\n",
    "\n",
    "# Step 3: Remove rows with missing data in relevant columns\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Step 4: Report missing data after cleaning\n",
    "missing_data_after = df_cleaned.isna().sum()\n",
    "print(\"\\nMissing data after cleaning:\")\n",
    "print(missing_data_after)\n",
    "\n",
    "# Display before and after DataFrames for comparison\n",
    "print(\"\\nOriginal DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3645e238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.describe():\n",
      "       popularity_score\n",
      "count          5.000000\n",
      "mean          80.000000\n",
      "std            7.905694\n",
      "min           70.000000\n",
      "25%           75.000000\n",
      "50%           80.000000\n",
      "75%           85.000000\n",
      "max           90.000000\n",
      "\n",
      "Grouped describe():\n",
      "         count  mean        std   min    25%   50%    75%   max\n",
      "species                                                        \n",
      "Bird       2.0  77.5  10.606602  70.0  73.75  77.5  81.25  85.0\n",
      "Cat        2.0  85.0   7.071068  80.0  82.50  85.0  87.50  90.0\n",
      "Dog        1.0  75.0        NaN  75.0  75.00  75.0  75.00  75.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Ensure pandas is imported\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'species': ['Cat', 'Cat', 'Dog', 'Dog', 'Bird', 'Bird', 'Bird'],\n",
    "    'popularity_score': [80, 90, 75, None, 85, None, 70]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# df.describe() - provides summary statistics for each column, including the count of non-missing values\n",
    "df_description = df.describe()\n",
    "\n",
    "# df.groupby('species')['popularity_score'].describe() - groups by species and gives summary statistics for popularity_score\n",
    "grouped_description = df.groupby('species')['popularity_score'].describe()\n",
    "\n",
    "print(\"df.describe():\")\n",
    "print(df_description)\n",
    "\n",
    "print(\"\\nGrouped describe():\")\n",
    "print(grouped_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f0dee",
   "metadata": {},
   "source": [
    "b. Mistype \"titanic.csv\" as \"titanics.csv\"\n",
    "If ChatBot troubleshooting is based on downloading the file, just replace the whole url with \"titanics.csv\" and try to troubleshoot the subsequent FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv' (assuming the file is indeed not present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8484121a",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 1. Overview of DataFrame Structure\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame Structure:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:372\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    371\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    373\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:274\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 1. Overview of DataFrame Structure\n",
    "print(\"DataFrame Structure:\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nData types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 2. Basic Descriptive Statistics\n",
    "print(\"\\nBasic Descriptive Statistics (for numerical columns):\")\n",
    "print(df.describe(include='all'))  # include='all' to get stats for all column types\n",
    "\n",
    "# 3. Counts of Unique Values for Categorical Columns\n",
    "print(\"\\nCounts of Unique Values for Categorical Columns:\")\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    print(f\"\\nValue counts for '{column}':\")\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddc2e5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Structure:\n",
      "Number of rows: 891\n",
      "Number of columns: 15\n",
      "\n",
      "Data types of each column:\n",
      "survived         int64\n",
      "pclass           int64\n",
      "sex             object\n",
      "age            float64\n",
      "sibsp            int64\n",
      "parch            int64\n",
      "fare           float64\n",
      "embarked        object\n",
      "class           object\n",
      "who             object\n",
      "adult_male        bool\n",
      "deck            object\n",
      "embark_town     object\n",
      "alive           object\n",
      "alone             bool\n",
      "dtype: object\n",
      "\n",
      "Basic Descriptive Statistics (for numerical columns):\n",
      "          survived      pclass   sex         age       sibsp       parch  \\\n",
      "count   891.000000  891.000000   891  714.000000  891.000000  891.000000   \n",
      "unique         NaN         NaN     2         NaN         NaN         NaN   \n",
      "top            NaN         NaN  male         NaN         NaN         NaN   \n",
      "freq           NaN         NaN   577         NaN         NaN         NaN   \n",
      "mean      0.383838    2.308642   NaN   29.699118    0.523008    0.381594   \n",
      "std       0.486592    0.836071   NaN   14.526497    1.102743    0.806057   \n",
      "min       0.000000    1.000000   NaN    0.420000    0.000000    0.000000   \n",
      "25%       0.000000    2.000000   NaN   20.125000    0.000000    0.000000   \n",
      "50%       0.000000    3.000000   NaN   28.000000    0.000000    0.000000   \n",
      "75%       1.000000    3.000000   NaN   38.000000    1.000000    0.000000   \n",
      "max       1.000000    3.000000   NaN   80.000000    8.000000    6.000000   \n",
      "\n",
      "              fare embarked  class  who adult_male deck  embark_town alive  \\\n",
      "count   891.000000      889    891  891        891  203          889   891   \n",
      "unique         NaN        3      3    3          2    7            3     2   \n",
      "top            NaN        S  Third  man       True    C  Southampton    no   \n",
      "freq           NaN      644    491  537        537   59          644   549   \n",
      "mean     32.204208      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "std      49.693429      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "min       0.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "25%       7.910400      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "50%      14.454200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "75%      31.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "max     512.329200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "\n",
      "       alone  \n",
      "count    891  \n",
      "unique     2  \n",
      "top     True  \n",
      "freq     537  \n",
      "mean     NaN  \n",
      "std      NaN  \n",
      "min      NaN  \n",
      "25%      NaN  \n",
      "50%      NaN  \n",
      "75%      NaN  \n",
      "max      NaN  \n",
      "\n",
      "Counts of Unique Values for Categorical Columns:\n",
      "\n",
      "Value counts for 'sex':\n",
      "sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'embarked':\n",
      "embarked\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'class':\n",
      "class\n",
      "Third     491\n",
      "First     216\n",
      "Second    184\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'who':\n",
      "who\n",
      "man      537\n",
      "woman    271\n",
      "child     83\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'deck':\n",
      "deck\n",
      "C    59\n",
      "B    47\n",
      "D    33\n",
      "E    32\n",
      "A    15\n",
      "F    13\n",
      "G     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'embark_town':\n",
      "embark_town\n",
      "Southampton    644\n",
      "Cherbourg      168\n",
      "Queenstown      77\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'alive':\n",
      "alive\n",
      "no     549\n",
      "yes    342\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 1. Overview of DataFrame Structure\n",
    "print(\"DataFrame Structure:\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nData types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 2. Basic Descriptive Statistics\n",
    "print(\"\\nBasic Descriptive Statistics (for numerical columns):\")\n",
    "print(df.describe(include='all'))  # include='all' to get stats for all column types\n",
    "\n",
    "# 3. Counts of Unique Values for Categorical Columns\n",
    "print(\"\\nCounts of Unique Values for Categorical Columns:\")\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    print(f\"\\nValue counts for '{column}':\")\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2681d14",
   "metadata": {},
   "source": [
    "c. Try to use a dataframe before it's been assigned into the variable\n",
    "You can simulate this by just misnaming the variable. For example, if you should write df.groupby(\"col1\")[\"col2\"].describe() based on how you loaded the data, then instead write DF.groupby(\"col1\")[\"col2\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78cf6d86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Df.describe() - provides summary statistics for each column, including the count of non-missing values\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m df_description \u001b[38;5;241m=\u001b[39m \u001b[43mDf\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Df.groupby('species')['popularity_score'].describe() - groups by species and gives summary statistics for popularity_score\u001b[39;00m\n\u001b[1;32m     14\u001b[0m grouped_description \u001b[38;5;241m=\u001b[39m Df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopularity_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'species': ['Cat', 'Cat', 'Dog', 'Dog', 'Bird', 'Bird', 'Bird'],\n",
    "    'popularity_score': [80, 90, 75, None, 85, None, 70]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Df.describe() - provides summary statistics for each column, including the count of non-missing values\n",
    "df_description = Df.describe()\n",
    "\n",
    "# Df.groupby('species')['popularity_score'].describe() - groups by species and gives summary statistics for popularity_score\n",
    "grouped_description = Df.groupby('species')['popularity_score'].describe()\n",
    "\n",
    "print(\"df.describe():\")\n",
    "print(df_description)\n",
    "\n",
    "print(\"\\nGrouped describe():\")\n",
    "print(grouped_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf45de8",
   "metadata": {},
   "source": [
    "d.Forget one of the parentheses somewhere the code\n",
    "For example, if the code should be pd.read_csv(url) the change it to pd.read_csv(url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecfa2354",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (156744971.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    df = pd.read_csv(url\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url\n",
    "\n",
    "# 1. Overview of DataFrame Structure\n",
    "print(\"DataFrame Structure:\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nData types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 2. Basic Descriptive Statistics\n",
    "print(\"\\nBasic Descriptive Statistics (for numerical columns):\")\n",
    "print(df.describe(include='all'))  # include='all' to get stats for all column types\n",
    "\n",
    "# 3. Counts of Unique Values for Categorical Columns\n",
    "print(\"\\nCounts of Unique Values for Categorical Columns:\")\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    print(f\"\\nValue counts for '{column}':\")\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f31e4138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.describe():\n",
      "       popularity_score\n",
      "count          5.000000\n",
      "mean          80.000000\n",
      "std            7.905694\n",
      "min           70.000000\n",
      "25%           75.000000\n",
      "50%           80.000000\n",
      "75%           85.000000\n",
      "max           90.000000\n",
      "\n",
      "Grouped describe():\n",
      "         count  mean        std   min    25%   50%    75%   max\n",
      "species                                                        \n",
      "Bird       2.0  77.5  10.606602  70.0  73.75  77.5  81.25  85.0\n",
      "Cat        2.0  85.0   7.071068  80.0  82.50  85.0  87.50  90.0\n",
      "Dog        1.0  75.0        NaN  75.0  75.00  75.0  75.00  75.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Import pandas library\n",
    "\n",
    "# Create an example DataFrame\n",
    "data = {\n",
    "    'species': ['Cat', 'Cat', 'Dog', 'Dog', 'Bird', 'Bird', 'Bird'],\n",
    "    'popularity_score': [80, 90, 75, None, 85, None, 70]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)  # Create DataFrame\n",
    "\n",
    "# df.describe() - provides summary statistics for each column, including the count of non-missing values\n",
    "df_description = df.describe()\n",
    "\n",
    "# df.groupby('species')['popularity_score'].describe() - groups by species and gives summary statistics for popularity_score\n",
    "grouped_description = df.groupby('species')['popularity_score'].describe()\n",
    "\n",
    "# Print the results\n",
    "print(\"df.describe():\")\n",
    "print(df_description)\n",
    "\n",
    "print(\"\\nGrouped describe():\")\n",
    "print(grouped_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86986d32",
   "metadata": {},
   "source": [
    "e.Mistype one of the names of the chained functions with the code\n",
    "For example, try something like df.group_by(\"col1\")[\"col2\"].describe() and df.groupby(\"col1\")[\"col2\"].describle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e70e08cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'readcsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadcsv\u001b[49m(url)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 1. Overview of DataFrame Structure\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame Structure:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'readcsv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.readcsv(url)\n",
    "\n",
    "# 1. Overview of DataFrame Structure\n",
    "print(\"DataFrame Structure:\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nData types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 2. Basic Descriptive Statistics\n",
    "print(\"\\nBasic Descriptive Statistics (for numerical columns):\")\n",
    "print(df.describe(include='all'))  # include='all' to get stats for all column types\n",
    "\n",
    "# 3. Counts of Unique Values for Categorical Columns\n",
    "print(\"\\nCounts of Unique Values for Categorical Columns:\")\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    print(f\"\\nValue counts for '{column}':\")\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5554e636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Structure:\n",
      "Number of rows: 891\n",
      "Number of columns: 15\n",
      "\n",
      "Data types of each column:\n",
      "survived         int64\n",
      "pclass           int64\n",
      "sex             object\n",
      "age            float64\n",
      "sibsp            int64\n",
      "parch            int64\n",
      "fare           float64\n",
      "embarked        object\n",
      "class           object\n",
      "who             object\n",
      "adult_male        bool\n",
      "deck            object\n",
      "embark_town     object\n",
      "alive           object\n",
      "alone             bool\n",
      "dtype: object\n",
      "\n",
      "Basic Descriptive Statistics (for numerical columns):\n",
      "          survived      pclass   sex         age       sibsp       parch  \\\n",
      "count   891.000000  891.000000   891  714.000000  891.000000  891.000000   \n",
      "unique         NaN         NaN     2         NaN         NaN         NaN   \n",
      "top            NaN         NaN  male         NaN         NaN         NaN   \n",
      "freq           NaN         NaN   577         NaN         NaN         NaN   \n",
      "mean      0.383838    2.308642   NaN   29.699118    0.523008    0.381594   \n",
      "std       0.486592    0.836071   NaN   14.526497    1.102743    0.806057   \n",
      "min       0.000000    1.000000   NaN    0.420000    0.000000    0.000000   \n",
      "25%       0.000000    2.000000   NaN   20.125000    0.000000    0.000000   \n",
      "50%       0.000000    3.000000   NaN   28.000000    0.000000    0.000000   \n",
      "75%       1.000000    3.000000   NaN   38.000000    1.000000    0.000000   \n",
      "max       1.000000    3.000000   NaN   80.000000    8.000000    6.000000   \n",
      "\n",
      "              fare embarked  class  who adult_male deck  embark_town alive  \\\n",
      "count   891.000000      889    891  891        891  203          889   891   \n",
      "unique         NaN        3      3    3          2    7            3     2   \n",
      "top            NaN        S  Third  man       True    C  Southampton    no   \n",
      "freq           NaN      644    491  537        537   59          644   549   \n",
      "mean     32.204208      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "std      49.693429      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "min       0.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "25%       7.910400      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "50%      14.454200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "75%      31.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "max     512.329200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "\n",
      "       alone  \n",
      "count    891  \n",
      "unique     2  \n",
      "top     True  \n",
      "freq     537  \n",
      "mean     NaN  \n",
      "std      NaN  \n",
      "min      NaN  \n",
      "25%      NaN  \n",
      "50%      NaN  \n",
      "75%      NaN  \n",
      "max      NaN  \n",
      "\n",
      "Counts of Unique Values for Categorical Columns:\n",
      "\n",
      "Value counts for 'sex':\n",
      "sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'embarked':\n",
      "embarked\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'class':\n",
      "class\n",
      "Third     491\n",
      "First     216\n",
      "Second    184\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'who':\n",
      "who\n",
      "man      537\n",
      "woman    271\n",
      "child     83\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'deck':\n",
      "deck\n",
      "C    59\n",
      "B    47\n",
      "D    33\n",
      "E    32\n",
      "A    15\n",
      "F    13\n",
      "G     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'embark_town':\n",
      "embark_town\n",
      "Southampton    644\n",
      "Cherbourg      168\n",
      "Queenstown      77\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'alive':\n",
      "alive\n",
      "no     549\n",
      "yes    342\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)  # Corrected the function name to 'read_csv'\n",
    "\n",
    "# 1. Overview of DataFrame Structure\n",
    "print(\"DataFrame Structure:\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nData types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 2. Basic Descriptive Statistics\n",
    "print(\"\\nBasic Descriptive Statistics (for numerical columns):\")\n",
    "print(df.describe(include='all'))  # include='all' to get stats for all column types\n",
    "\n",
    "# 3. Counts of Unique Values for Categorical Columns\n",
    "print(\"\\nCounts of Unique Values for Categorical Columns:\")\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    print(f\"\\nValue counts for '{column}':\")\n",
    "    print(df[column].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c3dbff",
   "metadata": {},
   "source": [
    "f. Use a column name that's not in your data for the groupby and column selection\n",
    "For example, try capitalizing the columns for example replacing \"sex\" with \"Sex\" in titanic_df.groupby(\"sex\")[\"age\"].describe(), and then instead introducing the same error of \"age\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36a415bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Species'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m df_description \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# df.groupby('species')['popularity_score'].describe() - groups by species and gives summary statistics for popularity_score\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m grouped_description \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSpecies\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopularity_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf.describe():\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_description)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8872\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8875\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Species'"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Ensure pandas is imported\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'species': ['Cat', 'Cat', 'Dog', 'Dog', 'Bird', 'Bird', 'Bird'],\n",
    "    'popularity_score': [80, 90, 75, None, 85, None, 70]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# df.describe() - provides summary statistics for each column, including the count of non-missing values\n",
    "df_description = df.describe()\n",
    "\n",
    "# df.groupby('species')['popularity_score'].describe() - groups by species and gives summary statistics for popularity_score\n",
    "grouped_description = df.groupby('Species')['popularity_score'].describe()\n",
    "\n",
    "print(\"df.describe():\")\n",
    "print(df_description)\n",
    "\n",
    "print(\"\\nGrouped describe():\")\n",
    "print(grouped_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d505f5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.describe():\n",
      "       popularity_score\n",
      "count          5.000000\n",
      "mean          80.000000\n",
      "std            7.905694\n",
      "min           70.000000\n",
      "25%           75.000000\n",
      "50%           80.000000\n",
      "75%           85.000000\n",
      "max           90.000000\n",
      "\n",
      "Grouped describe():\n",
      "         count  mean        std   min    25%   50%    75%   max\n",
      "species                                                        \n",
      "Bird       2.0  77.5  10.606602  70.0  73.75  77.5  81.25  85.0\n",
      "Cat        2.0  85.0   7.071068  80.0  82.50  85.0  87.50  90.0\n",
      "Dog        1.0  75.0        NaN  75.0  75.00  75.0  75.00  75.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Ensure pandas is imported\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'species': ['Cat', 'Cat', 'Dog', 'Dog', 'Bird', 'Bird', 'Bird'],\n",
    "    'popularity_score': [80, 90, 75, None, 85, None, 70]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# df.describe() - provides summary statistics for each column, including the count of non-missing values\n",
    "df_description = df.describe()\n",
    "\n",
    "# df.groupby('species')['popularity_score'].describe() - groups by species (lowercase 'species') and gives summary statistics for popularity_score\n",
    "grouped_description = df.groupby('species')['popularity_score'].describe()\n",
    "\n",
    "# Output the results\n",
    "print(\"df.describe():\")\n",
    "print(df_description)\n",
    "\n",
    "print(\"\\nGrouped describe():\")\n",
    "print(grouped_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c278573f",
   "metadata": {},
   "source": [
    "g. Forget to put the column name as a string in quotes for the groupby and column selection, and see if the ChatBot and google are still as helpful as they were for the previous question\n",
    "For example, something like titanic_df.groupby(sex)[\"age\"].describe(), and then titanic_df.groupby(\"sex\")[age].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1af37013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Structure:\n",
      "Number of rows: 891\n",
      "Number of columns: 15\n",
      "\n",
      "Data types of each column:\n",
      "survived         int64\n",
      "pclass           int64\n",
      "sex             object\n",
      "age            float64\n",
      "sibsp            int64\n",
      "parch            int64\n",
      "fare           float64\n",
      "embarked        object\n",
      "class           object\n",
      "who             object\n",
      "adult_male        bool\n",
      "deck            object\n",
      "embark_town     object\n",
      "alive           object\n",
      "alone             bool\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'age' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mData types of each column:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mdtypes)\n\u001b[0;32m---> 13\u001b[0m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[43mage\u001b[49m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 2. Basic Descriptive Statistics\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBasic Descriptive Statistics (for numerical columns):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'age' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 1. Overview of DataFrame Structure\n",
    "print(\"DataFrame Structure:\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nData types of each column:\")\n",
    "print(df.dtypes)\n",
    "df.groupby(\"sex\")[age].describe()\n",
    "\n",
    "# 2. Basic Descriptive Statistics\n",
    "print(\"\\nBasic Descriptive Statistics (for numerical columns):\")\n",
    "print(df.describe(include='all'))  # include='all' to get stats for all column types\n",
    "\n",
    "# 3. Counts of Unique Values for Categorical Columns\n",
    "print(\"\\nCounts of Unique Values for Categorical Columns:\")\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    print(f\"\\nValue counts for '{column}':\")\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f446b7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Structure:\n",
      "Number of rows: 891\n",
      "Number of columns: 15\n",
      "\n",
      "Data types of each column:\n",
      "survived         int64\n",
      "pclass           int64\n",
      "sex             object\n",
      "age            float64\n",
      "sibsp            int64\n",
      "parch            int64\n",
      "fare           float64\n",
      "embarked        object\n",
      "class           object\n",
      "who             object\n",
      "adult_male        bool\n",
      "deck            object\n",
      "embark_town     object\n",
      "alive           object\n",
      "alone             bool\n",
      "dtype: object\n",
      "\n",
      "Basic Descriptive Statistics (for numerical columns):\n",
      "          survived      pclass   sex         age       sibsp       parch  \\\n",
      "count   891.000000  891.000000   891  714.000000  891.000000  891.000000   \n",
      "unique         NaN         NaN     2         NaN         NaN         NaN   \n",
      "top            NaN         NaN  male         NaN         NaN         NaN   \n",
      "freq           NaN         NaN   577         NaN         NaN         NaN   \n",
      "mean      0.383838    2.308642   NaN   29.699118    0.523008    0.381594   \n",
      "std       0.486592    0.836071   NaN   14.526497    1.102743    0.806057   \n",
      "min       0.000000    1.000000   NaN    0.420000    0.000000    0.000000   \n",
      "25%       0.000000    2.000000   NaN   20.125000    0.000000    0.000000   \n",
      "50%       0.000000    3.000000   NaN   28.000000    0.000000    0.000000   \n",
      "75%       1.000000    3.000000   NaN   38.000000    1.000000    0.000000   \n",
      "max       1.000000    3.000000   NaN   80.000000    8.000000    6.000000   \n",
      "\n",
      "              fare embarked  class  who adult_male deck  embark_town alive  \\\n",
      "count   891.000000      889    891  891        891  203          889   891   \n",
      "unique         NaN        3      3    3          2    7            3     2   \n",
      "top            NaN        S  Third  man       True    C  Southampton    no   \n",
      "freq           NaN      644    491  537        537   59          644   549   \n",
      "mean     32.204208      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "std      49.693429      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "min       0.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "25%       7.910400      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "50%      14.454200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "75%      31.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "max     512.329200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "\n",
      "       alone  \n",
      "count    891  \n",
      "unique     2  \n",
      "top     True  \n",
      "freq     537  \n",
      "mean     NaN  \n",
      "std      NaN  \n",
      "min      NaN  \n",
      "25%      NaN  \n",
      "50%      NaN  \n",
      "75%      NaN  \n",
      "max      NaN  \n",
      "\n",
      "Counts of Unique Values for Categorical Columns:\n",
      "\n",
      "Value counts for 'sex':\n",
      "sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'embarked':\n",
      "embarked\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'class':\n",
      "class\n",
      "Third     491\n",
      "First     216\n",
      "Second    184\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'who':\n",
      "who\n",
      "man      537\n",
      "woman    271\n",
      "child     83\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'deck':\n",
      "deck\n",
      "C    59\n",
      "B    47\n",
      "D    33\n",
      "E    32\n",
      "A    15\n",
      "F    13\n",
      "G     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'embark_town':\n",
      "embark_town\n",
      "Southampton    644\n",
      "Cherbourg      168\n",
      "Queenstown      77\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'alive':\n",
      "alive\n",
      "no     549\n",
      "yes    342\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 1. Overview of DataFrame Structure\n",
    "print(\"DataFrame Structure:\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nData types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Group by 'sex' and get descriptive statistics for 'age'\n",
    "df.groupby(\"sex\")[\"age\"].describe()  # Fix: 'age' should be in quotes\n",
    "\n",
    "# 2. Basic Descriptive Statistics\n",
    "print(\"\\nBasic Descriptive Statistics (for numerical columns):\")\n",
    "print(df.describe(include='all'))  # include='all' to get stats for all column types\n",
    "\n",
    "# 3. Counts of Unique Values for Categorical Columns\n",
    "print(\"\\nCounts of Unique Values for Categorical Columns:\")\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    print(f\"\\nValue counts for '{column}':\")\n",
    "    print(df[column].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1db82a",
   "metadata": {},
   "source": [
    "9. Have you reviewed the course wiki-textbook and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?\n",
    "Yes\n",
    "ChatGPT Link: https://chatgpt.com/c/66e369f1-5c68-8013-9050-de0b35bb7eff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
