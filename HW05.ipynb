{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1d8ae8",
   "metadata": {},
   "source": [
    "Question 1\n",
    "The \"first pre-lecture video\" (above) describes hypothesis testing as addressing \"an idea that can be tested\", and the end of the video then discusses what our actual intended purpose in setting up a null hypothesis is. What is the key factor that makes the difference between ideas that can, and cannot be examined and tested statistically? What would you describe is the key \"criteria\" defining what a good null hypothesis is? And what is the difference between a null hypothesis and an alternative hypothesis in the context of hypothesis testing? Answer these questions with concise explanations in your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c0d551",
   "metadata": {},
   "source": [
    "In this scenario, I believed that the key factors for testing an idea statistically is whether it can be measured or observed. A hypothesis contains datasets that we can apply to conduct on experiments trials, and a good hypothesis should be specific, testable, and based on the assumption of no effect or relationship. In hypothesis testing, the null hypothesis H0 assumes no effect (the default), while the alternative hypothesis H1 suggests there is an effect or relationship. To test whether the hypothesis should reject or fail to reject, this comes to the calculation of the p-value, which is obtaining test results at least as extreme as the result actually observed, under the assumption that the null hypothesis is correct.If the so-called p-value of the system is greater/smaller what we usually call alpha which is the level of significance of the probability of obtaining your results due to chance, then we determine whether the conclusion approaches to null hypothesis or the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e77df",
   "metadata": {},
   "source": [
    "Question 2\n",
    "Towards the end of the \"first pre-lecture\" video (above) it is stated that, \"It is important to note that outcomes of tests refer to the population parameter, rather than the sample statistic! As such, the result that we get is for the population.\" In terms of the distinctions between the concepts of xi(standard deviation)'s, x̄(sample mean), μ(population mean), μ0 and, how would you describe what the sentence above means? Explain this concisely in your own words for a \"non-statsitical\" audience, defining the technical statistical terminology you use in your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b703e",
   "metadata": {},
   "source": [
    "In particular, in conducting statistical tests and experiments, what we're trying to identify is to determine a conclusion for the overall population based on the given small group samples we used in the test. \n",
    "Key terms explained:\n",
    "\n",
    "1. Sample statistic: This is a number that we calculate from a sample (a small group chosen from the population). An example is the sample mean (x̄), which is the average of the values in the sample.\n",
    "\n",
    "2. Population parameter: This is a number that describes the entire population. The population mean (μ) is the average of all values in the entire population.\n",
    "\n",
    "3. μ₀ (hypothesized population mean): This is the population mean we assume to be true before conducting the test.\n",
    "\n",
    "When we run a test, we use the sample statistic (like x̄) to make an estimate or decision about the population parameter (like μ). I mean, the real interesting facts wasn't in what happens in the sample but in what it tells us about the population as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6df51f",
   "metadata": {},
   "source": [
    "Question 3\n",
    "The second \"Pre-lecture\" video (above) explains that we \"imagine a world where the null hypothesis is true\" when calculating a p-value? Explain why this is in your own words in a way that makes the most sense to you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc6cb7",
   "metadata": {},
   "source": [
    "By all definitions, we based on the assumption that we imagine the world where there's no effect or difference. By doing this, we can see how likely our sample data is under this assumption. If the data we observe is very unlikely in this \"null world,\" it suggests that the null hypothesis might not be true, and we may lean towards the alternative hypothesis. Essentially, we're testing how well the data fits the \"no effect\" scenario.\n",
    "Basically, the reason why we start by assuming the null hypothesis H0 is true when calculating the p-value is that it provides a baseline or reference point. Let's say that your snacks that you put on the table this morning is gone. You assume that an individual must've took it. Following that, you then narrow down your suspects to one - which is your roommate. The null hypothesis H0 here is that he didn't take it, which we're based on the assumption of that he didn't. Or else, we need to have evidence to justify that he did, which is the alternative hypothesis H1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17abcca",
   "metadata": {},
   "source": [
    "Question 4\n",
    "The second \"Pre-lecture\" video (above) suggests that a smaller p-value makes the null hypothesis look more ridiculous. Explain why this is in your own words in a way that makes the most sense to you, clarifying the meaning of any technical statistical terminology you use in your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad193bc5",
   "metadata": {},
   "source": [
    "In simple terms, A smaller p-value means that the data we observed is very unlikely to occur if the null hypothesis (which assumes no effect or difference) were true, making us more likely to reject the null hypothesis. In other words, the smaller the p-value, the more it suggests that the assumption of the null hypothesis doesn't fit well with the data. This makes the null hypothesis look more ridiculous or implausible because the data seems too unusual for the \"no effect\" assumption to hold.\n",
    "Let's take an instance, based on the previous session of example, we're based on the null hypothesis that your roommate didn't steal your snacks. A smaller p-value which there's a low probability that he's telling the truth which he lied about he was at the dorm during that period of time when your snacks disappeared. This made the null hypothesis seem unreasonable and incomplete. Therefore, we reject the null hypothesis H0 which he is innocent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef55a43",
   "metadata": {},
   "source": [
    "Question 5\n",
    "Güntürkün (2003) recorded how kissing couples tilt their heads. 80 out of 124 couples, or 64.5% tilted their heads to the right. Simulate a p-value using a \"50/50 coin-flipping\" model for the assumption of the null hypothesis H0\n",
    " that the population of humans don't have left or right head tilt tendencies when kissing, and use the table below to determine the level of evidence we have against H0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2779e424",
   "metadata": {},
   "source": [
    "In this case, according to chatbot, to calculate the p-value, we can simulate how many times, under the null hypothesis (which assumes a 50/50 chance of tilting the head either left or right), a result as extreme as 80 out of 124 tilting to the right might occur.\n",
    "\n",
    "Here, the experiment trial process starts off with simulating a large number of samples of size 124, where each individual has a 50% chance of tilting their head to the right (like flipping a fair coin). Following that, we count how often the number of \"right-tilt\" individuals is equal to or greater than 80 in these simulations.\n",
    "Then, we estimate the p-value by dividing the number of simulations with 80 or more right-tilts by the total number of simulations. For this scenario, the p-value represents how likely it is to observe such a skew towards right-tilting by random chance alone.\n",
    "\n",
    "Based on the chatbot's caluculation, the simulated p-value is approximately 0.00087. This means that under the null hypothesis (assuming no left or right head tilt tendency), there's only about a 0.087% chance of observing 80 or more couples tilting their heads to the right purely by chance. With this p-value, the evidence against the null hypothesis is quite strong. Depending on the significance level ( 0.05, 0.01), this would likely be considered very strong evidence that people have a tendency to tilt their heads to the right when kissing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909ad74",
   "metadata": {},
   "source": [
    "Chatbot session: https://chatgpt.com/share/670f2f8c-0a24-8006-a4ba-08e61b65af98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a79aedd",
   "metadata": {},
   "source": [
    "Question 6\n",
    "Can a smaller p-value definitively prove that the null hypothesis is false? Is it possible to definitively prove that Fido (from the \"second pre-lecture video\") is innocent using a p-value? Is it possible to difinitively prove that Fido is guilty using a p-value? How low or high does a p-value have to be to definitely prove one or the other? Explain this concisely in your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18566d81",
   "metadata": {},
   "source": [
    "To me, a smaller p-value does not definitively prove that the null hypothesis H0 is false. In statistical testing, a p-value indicates that the probability of obtaining results at least as extreme as the observed data, assuming the null hypothesis is true. A very low p-value usually suggests that there's a strong evidence against the null hypothesis, but it does not prove it false. Here, it only indicates that the data is unlikely under the null hypothesis.\n",
    "\n",
    "In the context of proving whether Fido the dog is innocent or guility for flipping the garbage bin, a p-value cannot definitively prove either. If the p-value is low, it suggests the evidence against Fido didn't flip the garbage bin (the null hypothesis), but it doesn't offer a 100% certainty. Similarly, a high p-value does not definitively prove innocence either—it just means there's insufficient evidence, which is to fail to reject the null hypothesis H0.\n",
    "\n",
    "By the previous example, there is no threshold where a p-value alone can definitively prove innocence or guilt, as statistical significance only suggests likelihoods, not certainties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26ab42e",
   "metadata": {},
   "source": [
    "Question 7\n",
    "In the second half of the \"first pre-lecture video\" the concept of a \"one sided\" (or \"one tailed\") test is introduced in contrast to a \"two sided\" (or \"two tailed\") test. Work with a ChatBot to adjust the code from \"Demo II of the Week 5 TUT\" (which revisits the \"Vaccine Data Analysis Assignment\" from Week 04 HW \"Question 8\") in order to compute a p-value for a \"one sided\" (or \"one tailed\") hypothesis test rather than the \"two sided\" (or \"two tailed\") version it provides. Describe (perhaps with the help of your ChatBot) what changed in the code; how this changes the interpretation of the hypothesis test; and whether or not we should indeed expect the p-value to be smaller in the \"one tailed\" versus \"two tailed\" analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c50e8f7",
   "metadata": {},
   "source": [
    "Code below is generated and provided by the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73d6754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 2.5900615612703937\n",
      "One-tailed p-value: 0.014605261907746248\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data for health scores\n",
    "initial_health_scores = np.array([84, 78, 83, 81, 81, 80, 79, 85, 76, 83])\n",
    "final_health_scores = np.array([86, 86, 80, 86, 84, 86, 86, 82, 83, 84])\n",
    "\n",
    "# Difference between final and initial health scores\n",
    "diff = final_health_scores - initial_health_scores\n",
    "\n",
    "# Mean difference and standard error\n",
    "mean_diff = np.mean(diff)\n",
    "se = stats.sem(diff)\n",
    "\n",
    "# t-statistic\n",
    "t_stat = mean_diff / se\n",
    "\n",
    "# Degrees of freedom\n",
    "df = len(diff) - 1\n",
    "\n",
    "# One-tailed p-value (right-tailed test, assuming we are testing for improvement)\n",
    "p_value_one_tailed = 1 - stats.t.cdf(t_stat, df)\n",
    "\n",
    "# Output the t-statistic and p-value\n",
    "print(f\"t-statistic: {t_stat}\")\n",
    "print(f\"One-tailed p-value: {p_value_one_tailed}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cace1e",
   "metadata": {},
   "source": [
    "In particular, when interpreting the p-value for a two-tailed test, the p-value is computed by looking at both tails of the distribution (extreme values in both directions).\n",
    "- For a one-tailed test, we only consider one tail (values in one direction). As a result, we expect the p-value to be smaller in a one-tailed test because we're only focusing on one side of the distribution.\n",
    "\n",
    "In the modification of the code, we have to calculate the test statistic (mean difference): In both versions, you'll calculate the test statistic, such as the mean difference between initial and final health scores. This part of the code stays the same. Following that, in a two-tailed test, normally we calculate the probability of observing a value as extreme or more extreme than the test statistic in both directions. For a one-tailed test, usually we only look from one direction.\n",
    "\n",
    "For a one-tailed test, we only need to compute the cumulative distribution function (CDF) in one direction, as shown in the [stats.t.cdf()] function. For the two-tailed test, we were required to compute the p-value from both sides of the t-distribution, often by multiplying the one-tailed p-value by 2.\n",
    "\n",
    "In interpretation:\n",
    "- In the case of one-tailed test we focuse on whether the vaccine improves health.\n",
    "- In the case of two-tailed test would test for any significant change, whether improvement or worsening.\n",
    "\n",
    "To conclude the whole, by switching to a one-tailed test, we narrowing our major objectives to vaccine improvement. Because a one-tailed test looks at only one direction, the p-value will typically be smaller than in a two-tailed test, meaning it might more easily reject the null hypothesis if the vaccine is effective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bb5b6c",
   "metadata": {},
   "source": [
    "Chatbot session: https://chatgpt.com/share/670f350c-2f30-8006-8c17-d74f11957a5d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a4a013",
   "metadata": {},
   "source": [
    "Question 8\n",
    "Fisher's Tea Experiment\n",
    "Overview\n",
    "\n",
    "A most beloved piece of statistical lore about the (most famous) statistician Ronald Fisher involves cups of tea with milk. Fisher and his friend and colleague, Dr. Muriel Bristol, worked at Cambridge in the 1920s and regularly had tea together. During one of their afternoon tea times, Bristol refused a cup of tea from Fisher because he put milk in first BEFORE pouring in the tea. Bristol said she could taste the difference, and much preferred the taste of tea when the milk was poured in afterward the tea. Fisher didn't think that there could be a difference and proposed a hypothesis test to examine the situation.\n",
    "\n",
    "Fisher made 8 cups of tea, 4 with milk added in first and 4 with tea added in first, and gave them to Dr. Bristol without her seeing how they were made and she would say if she thought the tea or the milk was poured first. As it turned out, Bristol correctly identified if the tea or milk was poured first for all 8 of the cups. Fisher, being a skeptical statistician wanted to test if this could be happening by chance with Bristol just randomly guessing (or whether there was evidence against an assumption of Bristol just randomly guessing), and subsequently designed a statistical hypothesis test to do so.\n",
    "\n",
    "Suppose you run an experiment like this with students in STA130. You get a random sample of 80 STA130 students to each taste one cup of tea and tell you whether they think the milk or tea was poured first. Suppose 49 students are able to correctly state which was poured first. Provide a statistical analysis of this experiment as guided through the following set of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd168e9",
   "metadata": {},
   "source": [
    "In particular to this case. We assume that:\n",
    "Null Hypothesis (H₀): The students are guessing randomly, and the probability of correctly identifying whether milk or tea was poured first is 50%, which p=a, a = 0.05\n",
    "Alternative Hypothesis (H₁): The students are better than random guessing, and the probability of correctly identifying which was poured first is greater than 50%, which p>0.05\n",
    "\n",
    "The test procedure follows along if that\n",
    "- Each student is chosen at random and identifying independently\n",
    "- 10% condition, which n < 1/10N\n",
    "- The number of students correctly identifying the sequence follows a Binomial Distribution.\n",
    "\n",
    "For Test Statistic, Since we are dealing with proportions, we can use a z-test for the hypothesis test.\n",
    "p^ is the sample proportion (observed proportion of correct guesses),\n",
    "p0 is the hypothesized proportion under the null hypothesis,\n",
    "n is the sample size.\n",
    "\n",
    "Here are the calculation I conducted \n",
    "- p^ = 49/60 = 0.6125\n",
    "- p0 =0.5\n",
    "- n=80\n",
    "\n",
    "Since we're applying z-score test, the z-score for the test is approximately 2.01, and the corresponding p-value is approximately 0.022. In this case, p=0.022, alpha = 0.05. Give the conclusion that p<0.05\n",
    "Here, we're given conclusion that the p-value is smaller than the level of significane, which rejects the null hypothesis, resulting that the students are actually better than random guessing, which most likely they can taste the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a587eb2",
   "metadata": {},
   "source": [
    "Question 9\n",
    "Have you reviewed the course wiki-textbook and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31a1ab1",
   "metadata": {},
   "source": [
    "Yes, I have reviewed the course wiki-textbook and interacted with a ChatBot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
